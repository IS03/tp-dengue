# -*- coding: utf-8 -*-
"""
ETL Runner: Ejecuta el proceso completo de ETL
-----------------------------------------------
Script principal que coordina las fases de extracci√≥n, transformaci√≥n y carga
usando las funciones de los m√≥dulos extract.py, transform.py y load.py
"""

import os
import logging
import pandas as pd

# Importar funciones de los m√≥dulos ETL
from ETL.clima.b_transform import run_eda_transformations

# -----------------------------------------------------------------------------
# Configuraci√≥n de logging
# -----------------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
log = logging.getLogger(__name__)

# -----------------------------------------------------------------------------
# Configuraci√≥n de rutas
# -----------------------------------------------------------------------------
INPUT_PARQUET = "data/datos-todas-estaciones.parquet"
OUTPUT_PARQUET = "data/datos_clima_transformados.parquet"

# -----------------------------------------------------------------------------
# Funci√≥n principal del ETL
# -----------------------------------------------------------------------------
def run_etl():
    """
    Ejecuta el proceso completo de ETL: Extract, Transform, Load.
    """
    try:
        log.info("üöÄ Iniciando proceso ETL completo...")

        # 1) Verificar que existe el archivo de datos
        if not os.path.exists(INPUT_PARQUET):
            log.error(f"‚ùå No se encontr√≥ el archivo de datos: {INPUT_PARQUET}")
            return False
        else:
            log.info("üì¶ Archivo de datos encontrado")

        # 2) Leer datos extra√≠dos
        log.info("üìñ Leyendo datos crudos...")
        df_raw = pd.read_parquet(INPUT_PARQUET)
        log.info(f"üìä Datos crudos: {len(df_raw)} filas, {len(df_raw.columns)} columnas")

        # 3) TRANSFORM: Aplicar transformaciones
        log.info("üîÑ Aplicando transformaciones...")
        df_transformed = run_eda_transformations(df_raw)
        log.info(f"‚ú® Datos transformados: {len(df_transformed)} filas, {len(df_transformed.columns)} columnas")

        # 4) LOAD: Guardar datos transformados en Parquet
        log.info("üíæ Guardando datos transformados en Parquet...")
        df_transformed.to_parquet(OUTPUT_PARQUET, index=False)
        log.info(f"‚úÖ Datos guardados en: {OUTPUT_PARQUET}")

        # Estad√≠sticas finales
        print("\n" + "="*50)
        print("ESTADISTICAS DEL PROCESO ETL")
        print("="*50)
        print(f"Registros transformados: {len(df_transformed)}")
        print(f"Estaciones procesadas: {df_transformed['id_estacion'].nunique()}")
        print(f"Rango de fechas: {df_transformed['fecha'].min()} - {df_transformed['fecha'].max()}")
        print(f"Archivo Parquet generado: {OUTPUT_PARQUET}")
        print("="*50)

        log.info("‚úÖ Proceso ETL completado exitosamente!")
        return True

    except Exception as e:
        log.error(f"üí• Error cr√≠tico en ETL: {e}")
        return False

# -----------------------------------------------------------------------------
# Main
# -----------------------------------------------------------------------------
if __name__ == "__main__":
    success = run_etl()
    exit(0 if success else 1)